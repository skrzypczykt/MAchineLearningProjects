{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zadanie.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skrzypczykt/MAchineLearningProjects/blob/main/NeuralNetworksTutorials/TFLearn/Zadanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1KATslZWXXN"
      },
      "source": [
        "# Runtime i instalacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0r_G8i3xZ6X"
      },
      "source": [
        "Zacznijmy od włączenia wsparcia obliczeń kartą graficzną (GPU), która znacznie przyspieszy nasze działania. Może się zdażyć, że nie będzie dostępnych GPU w Colaboratory – wtedy można pracować bez niego, jedynie obliczenia potrwają kilka razy dłużej.\n",
        "\n",
        "Wybieramy w menu **`Runtime`** -> **`Change runtime type`** , a następnie w podmenu **`Hardware accelerator`** wybieramy **`GPU`**.\n",
        "\n",
        "\n",
        "<img style=\"float:left\" src=\"https://www.mimuw.edu.pl/~mm319369/priv/d73890416bec03ff3e2b3756af8c941c/images/change-runtime1.png\">\n",
        "<img src=\"https://www.mimuw.edu.pl/~mm319369/priv/d73890416bec03ff3e2b3756af8c941c/images/change-runtime2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KtARNGjy38J"
      },
      "source": [
        "## TFlearn\n",
        "\n",
        "W tym zadaniu będziemy uczyć sieci neuronowe i obserwować jak zachowują się, gdy zmieniamy liczbę neuronów w sieci, funkcje aktywacji i co się dzieje, gdy sieć jest za duża względem danych. Wasze zadanie będzie polegało na odpowiedniej konfiguracji sieci, a następnie narysowaniu wykresów zaobserwowanych rezultatów.\n",
        "\n",
        "Będziemy korzystać z biblioteki [*tflearn*](http://tflearn.org/getting_started/), która jest prostym interfejsem do `tensorflow`.\n",
        "\n",
        "Poniżej ją instalujemy i importujemy potrzebne biblioteki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsR41LUrWXXW"
      },
      "source": [
        "!pip install tflearn \"tensorflow<2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zMPID31WXXe"
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.normalization import local_response_normalization\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Monkey-patchujemy tflearn, żeby nie wypisywał samemu statystyk,\n",
        "# któe nie działają dobrze w colaboratory\n",
        "tflearn.callbacks.TermLogger.print_termlogs = lambda *args, **kwargs: None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhVTdq7Z0ama"
      },
      "source": [
        "# Zbiór danych (dataset)\n",
        "\n",
        "Będziemy pracować na już tradycyjnym zbiorze – rozpoznawania odręcznie pisanych cyfr [MNIST](http://yann.lecun.com/exdb/mnist/).\n",
        "Elementy tego zbioru to obrazki 28x28 pikseli w skali szarości, a ich etykietami są cyfry im odpowiadające. Mamy 55000 przykładów treningowych i 10000 przykładów testowych.\n",
        "Dla wydajności obliczeń, wszystkie dane są umieszczane w dużych macierzach (tablicach).\n",
        "\n",
        "Poniższa komórka pobiera i ładuje zbiór danych do pamięci. Wyjaśnienie wprowadzonych zmiennych poniżej.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7FDEJ_dWXXi"
      },
      "source": [
        "# Tu ładujemy nasz dataset - zestaw odręcznie pisanych cyfr od 0 do 9\n",
        "\n",
        "\n",
        "import tflearn.datasets.mnist as mnist\n",
        "X, Y, testX, testY = mnist.load_data(one_hot=True) # ładowanie datasetu (automatycznie ściąga się z internetu)\n",
        "\n",
        "# X,Y to dane treningowe\n",
        "# testX, textY to dane walidacyjne - sprawdzamy nimi jak dobra jest nasza sieć\n",
        "\n",
        "# nasze obrazy mają mieć wymiar 28x28 pikseli - będziemy używać sieci konwolucyjnych, więc konieczna \n",
        "# jest zmiana wymiarów macierzy poleceniem reshape\n",
        "# [samples, x_size, y_size, channels]\n",
        "# samples - liczba próbek \n",
        "# x_size, y_size - wymiary obrazka\n",
        "# channels - liczba kolorów/kanałów - w naszym przypadku 1, bo obrazki są czarno-białe\n",
        "X = X.reshape([-1, 28, 28, 1])\n",
        "testX = testX.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlUYUqFU10a5"
      },
      "source": [
        "**X** oraz **testX** to 4-wymiarowe macierze z przykładami odpowiednio treningowymi i testowymi. Wymiary tych macierzy to \\[*liczba przykładów*, *rozmiar x*, *rozmiar y*, *liczba kolorów*]. Różne funkcje oczekują odpowiednich wymiarów macierzy. Nie będzie to na szczęście dla nas istotne poza zrozumieniem napisów, które się pojawiają:\n",
        "\n",
        "`X[4]`  - przykład numer 4 (wymiar [28, 28, 1]) \\\\\n",
        "`X[2:3]`  - przykład numer 2, ale w wymiarze [1, 28, 28, 1] - odpowiednie dla funkcji/metod tflearn \\\\\n",
        "`X[:10]`  - przykłady numer 0...9, w wymiarze [10, 28, 28, 1] \\\\\n",
        "`X[2,:,:,0]` - przykład 2 w w wymiarze [28, 28] odpowiednim dla funkcji do rysowania\n",
        "\n",
        "**Y** oraz **testY** to 2-wymiarowe macierze z etykietami odpowiednio treningowymi i testowymi. Wymiary tych macierzy to \\[*liczba przykładów*, *liczba cyfr*]. Te macierze reprezentują tzw. kodowanie *one-hot* etykiet  - dany przykład przedstawiający cyfrę **i** ma **1** na **i**-tej pozycji, a na pozostałych **0**.\n",
        "\n",
        "`Y[0]` - etykieta przykładu numer 0 (wymiar [10]) \\\\\n",
        "`Y[2:3]` - etykieta przykładu numer 2, ale w wymiarze [1, 10] - odpowiednie dla funkcji/metod tflearn \\\\\n",
        "`Y[:10]` - etykiety dla przykładów numer 0..9 (j.w.)\n",
        "\n",
        "Poniżej przykład użycia na przykładach numer 0 i 1 (powinny reprezentować 7 i 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMQYaB8RWXXm"
      },
      "source": [
        "# Kilka przykładów z naszego datasetu\n",
        "print(Y[0]) # etykieta - 1 tam, gdzie poprawna klasa\n",
        "plt.imshow(X[0,:,:,0], cmap='gray') # reprezentacja graficzna obrazka\n",
        "plt.show()\n",
        "\n",
        "print(Y[1])\n",
        "plt.imshow(X[1,:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5SjssyP5ppZ"
      },
      "source": [
        "# Budowa sieci\n",
        "\n",
        "Zdefiniujmy najpierw klasę pomocniczną, która będzie przetrzymywać wyniki obliczeń i przyda nam się do wykresów. Opiszemy ją później."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xx9TUguWXXq"
      },
      "source": [
        "# Definiujemy klasę, która będzie przetrzymywać wyniki obliczeń po każdej epoce\n",
        "class Stats(tflearn.callbacks.Callback):\n",
        "    def __init__(self, examples=0):\n",
        "        self.epoch_data = []\n",
        "        self.data_size = examples\n",
        "        self.last_time = 0\n",
        "        self.start_time = 0\n",
        "        \n",
        "        self.min_report_secs = 1.\n",
        "\n",
        "    def on_train_begin(self, training_state):\n",
        "        self.start_time = time.time()\n",
        "      \n",
        "    def on_epoch_end(self, training_state):\n",
        "        metrics = {\n",
        "            'loss': training_state.loss_value, # loss (strata) dla danych treningowych\n",
        "            'acc': training_state.acc_value,   # accuracy (dokładność) dla danych treningowych\n",
        "            'val_loss': training_state.val_loss, # loss dla danych walidacyjnych\n",
        "            'val_acc': training_state.val_acc, # accuracy dla danych walidacyjnych\n",
        "            'epoch': training_state.epoch,\n",
        "            'step': training_state.step,\n",
        "            'iter': training_state.current_iter,\n",
        "            'time': time.time() - self.start_time,\n",
        "        }\n",
        "\n",
        "        self.epoch_data.append(metrics)\n",
        "        \n",
        "    def on_batch_end(self, training_state, snapshot=False):\n",
        "      cur_time = time.time()\n",
        "      if cur_time - self.last_time < self.min_report_secs:\n",
        "        return # nie spamujmy za często\n",
        "      \n",
        "      self.last_time = cur_time\n",
        "      epoch = training_state.epoch\n",
        "      step = training_state.step\n",
        "      iter = training_state.current_iter\n",
        "      print(\"Epoch %d, step (batch no.): %d -- acc: %.2f, loss %.2f -- iter %05d/%05d, training for: %.2fs\" % (\n",
        "          epoch, step, training_state.acc_value, training_state.loss_value,\n",
        "          iter, self.data_size, cur_time-self.start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jS6wmQ76KYB"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Poniżej jest przykład budowy sieci przy korzystaniu z `tflearn`. W zadaniu będzie trzeba zmieniać odpowiednie parametry.\n",
        "\n",
        "Sieć budujemy kolejnymi warstwami, gdzie funkcja tworząca następną warstwę przyjmuje zmienną reprezentującą poprzednią. Dla wygody wynik przypisujemy na tą samą zmienną, aby móc łatwo dodawać dodatkowe warstwy poprzez wklejenie kodu w odpowiednie miejsce:\n",
        "\n",
        "`network = ...` <- opis warstwy A \\\\\n",
        "`network = conv_2d(network, ...)` <- tworzymy nową warstwę B za warstwą A i przypisujemy na tą samą zmienną (nie potrzebujemy już odwoływać się do warstwy A) \\\\\n",
        "`network = fully_connected(network, ...)` <- warstwa C za warstwą B\n",
        "\n",
        "W tym momencie zmienna `network` reprezentuje sieć składającą się z warstw `A-B-C`.\n",
        "\n",
        "### Uczenie\n",
        "\n",
        "Uczenie sieci przebiega w fazach. Podajemy sieci przykłady kolejno i stosujemy propagację wstęczną. W momencie, gdy przykłady nam się skończą, po prostu zaczynamy od nowa. Każdy taki obrót będziemy nazywali **epoką**.  \\\\\n",
        "Przykładów nie będziemy podawać sieci pojedynczo – podajemy je w porcjach rozmiaru `batch` (*wsad*), co oznacza ile przykładów sieć będzie przetwarzać jednocześnie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k98UrH789LXm"
      },
      "source": [
        "Przydatne nam będą przede wszystkim funkcje:\n",
        "\n",
        "`conv_2d(network, #filtrów, #rozmiar, activation=f.aktywacji, regularizer=\"L2\")` - tworzy nową warstwę konwolucyjną posiadającą `#filtrów` filtrów (neuronów) o rozmiarze `#rozmiar x #rozmiar` oraz z funkcją aktywacji jak podana. Wartości `regularizer` nie należy zmieniać w tym zadaniu.\n",
        "\n",
        "`max_pool_2d(network, #rozmiar)` - podpróbkowanie danych co `#rozmiar` (zmniejsza wymiar obrazka razy `#rozmiar`)\n",
        "\n",
        "`fully_connected(network, #neuronów, activation=f.aktywacji)` - warstwa pełna  z `#neuronów` neuronów i podaną funkcją aktywacji.\n",
        "\n",
        "**W kodzie zaznaczono, który fragment będzie podlegał modyfikacji.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmB2p2qIWXXt"
      },
      "source": [
        "# Tu definiujemy architekturę naszej sieci\n",
        "\n",
        "# !!! UWAGA - przy każdych nowych obliczeniach należy zresetować graf sieci\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Wyłączamy warningi z tensorflow\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "# Warstwa wejściowa - musi mieć takie same wymiary jak dane\n",
        "network = input_data(shape=[None, 28, 28, 1], name='input') # None oznacza, że ta \n",
        "# wartość będzie uzupełniona automatyzcnie i jest to liczba próbek we wsadzie (batch)\n",
        "\n",
        "### MODYFIKUJEMY OD TĄD\n",
        "# ---\n",
        "# Pierwsza warstwa konwolucyjna - 32 filtry o rozmiarach 3x3\n",
        "# z funkcją aktywacji (activation=) relu.\n",
        "# Regularizer='L2' oznacza narzucenie ograniczenia na wartości wag (nie istotne tutaj).\n",
        "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
        "# max_pool wykonuje podpróbkowanie danych - zmniejsza wymiar obrazka 2-krotnie\n",
        "network = max_pool_2d(network, 2) # teraz obrazki są [14x14]\n",
        "\n",
        "# druga warstwa konwolucyjna - 32 filtry o rozmiarach 3x3 z podpróbkowaniem\n",
        "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
        "network = max_pool_2d(network, 2) # teraz obrazki są [7x7]\n",
        "\n",
        "# warstwa pełna - tu już zaczyna się \"normalna\" sieć neuronowa\n",
        "network = fully_connected(network, 128, activation='relu') # 128 neuronów, aktywacja \"relu\", przyjmuje wejście [7x7] do [128] neuronów\n",
        "network = fully_connected(network, 256, activation='relu') # 256 neuronów, aktywacja \"relu\"\n",
        "# ---\n",
        "### DO TĄD\n",
        "\n",
        "# warstwa wyjściowa - używamy aktywacji softmax, żeby dostać prawdopodobieństwa dla każdej klasy (cyfry)\n",
        "network = fully_connected(network, 10, activation='softmax')\n",
        "\n",
        "# tu definiujemy w jaki sposób optymalizować sieć (regression nie oznacza, że robimy regresję)\n",
        "# nie będziemy modyfikować tych argumentów; stosujemy optymizator Adam\n",
        "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
        "                     batch_size=250,\n",
        "                     loss='categorical_crossentropy', name='target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abynHGxHGoa7"
      },
      "source": [
        "Powyżej zdefiniowaliśmy sieć z warstwą wejściową, dwiema warstwami konwolucyjnymi z 32 filtrami 3x3 i podpróbkowaniem x2 oraz trzema warstwami pełnymi z odpowiednio 128, 256 i 10 neuronami."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x35TeBBk_ynp"
      },
      "source": [
        "## Trenowanie sieci\n",
        "\n",
        "Trenowanie sieci wywołujemy jak poniżej (wszystkie 3 linijki będą potrzebne). Trenowanie możemy w dowolnym momencie przerwać klikając na kwadrat zatrzymywania.\n",
        "\n",
        "Metoda uczenia ma następującą sygnaturę:\n",
        "`model.fit({'input': X}, {'target': Y}, n_epoch=#epok,\n",
        "           validation_set=({'input': testX}, {'target': testY}), show_metric=True, callbacks=[scores])`\n",
        "  \n",
        " Uczy podaną wyżej sieć, z danymi treningowymi z `X` i etykietami z `Y` przez `#epok` epok. Wyniki walidacji będą obliczane na zbiorze testowym `testX` z etykietami `testY`. Resztę zostawiamy bez zmian – służy do wypisywania i rejestrowania statystyk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY8evjU6De6R"
      },
      "source": [
        "Podczas uczenia będziemy zbierali miary tego, jak sieć radzi sobie z naszymi danymi:\n",
        "\n",
        " `loss` - loss (strata) dla danych treningowych \\\\\n",
        "`acc` - accuracy (dokładność) dla danych treningowych \\\\\n",
        "`val_loss` -  loss dla danych walidacyjnych \\\\\n",
        "`val_acc` - accuracy dla danych walidacyjnych \\\\\n",
        "`epoch` - numer *epoki* \\\\\n",
        "`step` - numer wsadu (*batch*) \\\\\n",
        "`iter` - liczba widzianych przykładów \\\\\n",
        "`time` - czas jaki upłynął od początku uczenia \\\\\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kTeJDOjEs3m"
      },
      "source": [
        "**Uwaga!** kolejne wywołania poniższej komórki będą *douczać* sieć – aby uczyć ją od nowa musimy ponownie wykonać komórkę z definicją sieci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAabxPtCWXXy"
      },
      "source": [
        "# uruchamiamy trenowanie naszej sieci\n",
        "# n_epoch - liczba epok, czyli przejść przez cały zbiór danych treningowych\n",
        "scores = Stats(examples=len(X))\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
        "model.fit({'input': X}, {'target': Y},\n",
        "          n_epoch=20,  # <-- DO ZMIANY\n",
        "          validation_set=({'input': testX}, {'target': testY}), show_metric=True, callbacks=[scores])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB_tk_6YDJ4b"
      },
      "source": [
        "## Korzystanie z sieci\n",
        "\n",
        "Poniźej przykład korzystania z sieci do etykietowania danych które sieć nie widziała."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NchiBGf5WXX3"
      },
      "source": [
        "# Wylosujmy index elementu ze zbioru testowego do sprawdzenia\n",
        "test_index = np.random.randint(len(testX))\n",
        "# Przewidywania modelu na danych walidacyjnych (prawdopodobieństwa/logika rozmyta):\n",
        "predictions = model.predict(testX[test_index:test_index+1])\n",
        "plt.imshow(testX[test_index,:,:,0], cmap='gray')\n",
        "plt.show()\n",
        "print(predictions)\n",
        "print(\"Prawdopodobnie: %s na %.3f%%\" % (predictions.argmax(), predictions.max()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JszN8lhFpKw"
      },
      "source": [
        "# Programatyczny dostęp do statystyk\n",
        "\n",
        "Statystyki znajdziemy w obiekcie `scores`, który przekazaliśmy podczas uczenia sieci. Jest to lista statystyk po każdej *epoce*. Statystyki reprezentowane są przez słownik z polami jak opisanymi wcześniej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71uFUDO5WXX7"
      },
      "source": [
        "# wyświetlenie danych\n",
        "scores.epoch_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwhTLw0PWXX_"
      },
      "source": [
        "# POLECENIA\n",
        "## Do zaliczenia tego zadania można zrobić podzadania A-C lub zadanie alternatywne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCZmKjv9WXYA"
      },
      "source": [
        "# Uwagi:\n",
        "\n",
        "### Przy każdych nowych obliczeniach należy zresetować graf sieci.\n",
        "### Nie należy zmieniać linijki z optymizatorem przy rozwiązywaniu zadań.\n",
        "### Niektóre rezultaty mogą być nieintuicyjne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q5fPv0hWXYB"
      },
      "source": [
        "# Zadanie A: dawne ograniczenia\n",
        "\n",
        "Narysuj wykres zależności accuracy dla danych **walidacyjnych** (val_acc) od liczby epok (max 10 epok)\n",
        "dla sieci w dwóch wariantach:\n",
        "* 1 warstwa konwolucyjna: 32 filtry 3x3 + 2 warstwy pełne (jak w przykładzie: 128,256,10)\n",
        "* j.w. ale dla 3 i 5 warstw konwolucyjnych (podpróbkowanie wykonuj tylko po 2. i 4. warstwie konwolucyjnej)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-gTz-gIWXYC"
      },
      "source": [
        "# Zadanie B - funkcje aktywacji\n",
        "\n",
        "Narysuj wykres zależności accuracy dla danych **walidacyjnych** (val_acc) od liczby epok, dla sieci konwolucyjnej: \n",
        "32-3x3, podpróbkowanie x2, 32-3x3, podpróbkowanie x2, 32-3x3, z wartstwami pełnymi: 128, 256, 10\n",
        "\n",
        "(przez 32-3x3 rozumiemy warstwę konwolucyjną z 32 filtrami rozmiaru 3x3)\n",
        "\n",
        "w zależności od funkcji aktywacji (ustawianej w parametrze `activation=`):\n",
        "* `'relu'`\n",
        "* `'sigmoid'`\n",
        "* `'elu'`\n",
        "\n",
        "** Uwaga! ** Nie należy zmieniać funkcji aktywacji `softmax` w ostatniej warstwie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OX8igExWXYD"
      },
      "source": [
        "# Zadanie C: overfitting\n",
        "Narysuj wykres zależności accuracy dla danych **treningowych** (acc) i **walidacyjnych** (val_acc) od liczby epok (50 epok), dla sieci która ma tylko jedną ukrytą pełną warstwę z 1000 neuronów z aktywacją `relu` i warstwę wyjściową z 10 neuronami. \n",
        "\n",
        "Obliczenia wykonaj używając tylko 1000 pierwszych próbek z zestawu treningowego, jak pokazano poniżej:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTIy2YLtWXYG"
      },
      "source": [
        "scores = Stats(1000)\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
        "model.fit({'input': X[:1000]}, {'target': Y[:1000]}, n_epoch=50,\n",
        "           validation_set=({'input': testX}, {'target': testY}), show_metric=True, callbacks=[scores])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiYHti3sWXYL"
      },
      "source": [
        "# Przesyłanie rozwiązań\n",
        "\n",
        "Zadania należy wysyłać na adresy `slezak@mimuw.edu.pl` i `m.matraszek@mimuw.edu.pl`  z tytułem o przedrostku [SI20-3]. \n",
        "Przesłane wykresy mogą być w dowolnej formie. Mile widziany byłby odpowiednio zmieniony ten notebook. Poniżej można znaleźć prosty sposób rysowania wykresów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegIH-JjWXYN"
      },
      "source": [
        "# Przykład użycia matplotlib do rysowania wykresów:\n",
        "\n",
        "# Wartości w punktach [0, 1, 2, ...]; podajemy tylko Y\n",
        "plt.plot([0, 1, 1.5, 6], label=\"asd\")\n",
        "# X podany w pierwszym argumencie, Y w drugim\n",
        "plt.plot([0, 2, 6], [7, 0, 0.6], label=\"bbb\")\n",
        "# rysuje legendę (linie podpisane jako `label`)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rlAMKVbWXYY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhsINoKVWXYb"
      },
      "source": [
        "# Zadanie alternatywne\n",
        "\n",
        "Zamiast rozwiązywania powyższych zadań, proponujemy też kontynuację przygody z OpenAI Gym.\n",
        "W tej wersji chcielibyśmy użyć dość prostej metody łączącej uczenie ze wzmocnieniem i sieci neuronowe. Jest to Policy Gradient. W miarę przystępny opis tej metody jest zamieszczony tutaj: http://karpathy.github.io/2016/05/31/rl/\n",
        "\n",
        "Używając tflearn z tą metodą, rozwiąż środowisko CartPole-v0 z OpenAI Gym. A może nawet coś trudniejszego?\n",
        "Wykonanie:\n",
        "```python\n",
        "model.fit({'input': X}, {'target': Y}, n_epoch=1)\n",
        "```\n",
        "pozwoli na jednokrotną iterację propagacji wstecznej na podanych danych. Metodę tę można wykonać ponownie z innymi danymi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZUjO3qgPqM5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}