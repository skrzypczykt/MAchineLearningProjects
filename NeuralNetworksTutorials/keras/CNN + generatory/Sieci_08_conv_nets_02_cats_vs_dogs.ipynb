{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Sieci_08_conv_nets_02_cats_vs_dogs.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skrzypczykt/MAchineLearningProjects/blob/main/NeuralNetworksTutorials/keras/CNN%20%2B%20generatory/Sieci_08_conv_nets_02_cats_vs_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3g71Hi-4XN"
      },
      "source": [
        "# Sieci splotowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4-pbMO-4XQ"
      },
      "source": [
        "Sieci neuronowe są bardzo często wykorzystywane do analizy obrazu albo dźwięku. Nie wykorzystuje się wtedy zwykłych sieci sekwencyjnych o połączeniach każdy z każdym:\n",
        "* do analizy obrazu używa się splotowych (*konwolucyjnych*) sieci neuronowych (*convolutional neural networks*, **CNN**)\n",
        "* do analizy dźwięku używa się często splotowych sieci rekurencyjnych (*recurrent neural networks*, **RNN**)\n",
        "\n",
        "My jednak zrobimy coś nieco ciekawszego/zabawniejszego, pobawimy się w rozpoznawanie czy na zdjęciu jest pies czy kot.  \n",
        "\n",
        "Link do danych dostaliście mailem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHibcMFA-4XR"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m36xJzDv-4XS"
      },
      "source": [
        "Wczytujemy nazwy plików graficznych. Jako `cat_dir` oraz `dog_dir` wprowadź ścieżkę do folderu treningowego `psy_vs_koty` odpowiednio z kotami i psami."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uleAoPu--4XS"
      },
      "source": [
        "cat_dir = r'_____'\n",
        "dog_dir = r'_____'\n",
        "cat_images = os.listdir(_____)\n",
        "dog_images = os.listdir(_____)\n",
        "\n",
        "# wyświetlamy podsumowanie\n",
        "print('Obrazy psów:', ', '.join(dog_images[:3]), '... razem {}'.format(len(dog_images)))\n",
        "print('Obrazy kotów:', ', '.join(cat_images[:3]), '... razem {}'.format(len(cat_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywAwgPKR-4XT"
      },
      "source": [
        "Tworzymy funkcję do wyświetlania zdjęć (tutaj nic nie musicie zmieniać, ale przejrzyjcie kod aby mieć ogólne zrozumienie co robi):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RcSUM7D-4XU"
      },
      "source": [
        "import os.path as op\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "def show_image(image_type, image_index, target_size=None):\n",
        "    # ogarniamy ścieżki\n",
        "    img_dirs = {'cat': cat_dir, 'dog': dog_dir}\n",
        "    fname = '.'.join([image_type, str(image_index), 'jpg'])\n",
        "    full_img_path = op.join(img_dirs[image_type], fname)\n",
        "\n",
        "    # wczytujemy plik\n",
        "    img = load_img(full_img_path, target_size=target_size)\n",
        "    \n",
        "    # wyświetlamy\n",
        "    plt.imshow(img)\n",
        "    plt.title(fname)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnE-ab18-4XU"
      },
      "source": [
        "Wyświetlamy wybrane zdjęcie podając do funkcji rodzaj zdjęcia (`'cat'` albo `'dog'`) oraz jego identyfikator numeryczny (np. `23`). Spróbuj poniżej wyświetlić zdjęcie `cat.4586.jpg`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5JUOgNe-4XV"
      },
      "source": [
        "image_type = ____\n",
        "image_index = ____\n",
        "show_image(image_type, image_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTsVeiz4-4XV"
      },
      "source": [
        "Zmień kod poniżej aby wczytać inne zdjęcie. Zrób tak kilka razy aby przejrzeć różne zdjęcia.\n",
        "* Przejrzyj co najmniej 3 zdjęcia kotów i 3 zdjęcia psów - jak porównałabyś/porównałbyś zróżnicowanie i złożoność obrazów psów i kotów w porównaniu do poprzedniego datasetu, Fashion MNIST?\n",
        "* Do datasetu, z którego korzystamy zgłaszane były problemy. Sprawdź pliki omawiane w komentarzach poniżej:\n",
        "  > Image cat.7377.jpg is labelled as a cat. However it is a person. Not a dog, not a cat. Why is it in the data?\n",
        "  \n",
        "  oraz:\n",
        "  \n",
        "  > Unless there is a cat in 1 pixel of this image I can't see, image cat.4085.jpg is clearly a dog to me.\n",
        "  \n",
        "* Sprawdź jeszcze co najmniej 3 z poniższych zdjęć:\n",
        "  - cat.4338.jpg\n",
        "  - dog.1043.jpg\n",
        "  - dog.1773.jpg\n",
        "  - cat.3216.jpg\n",
        "  - cat.4688.jpg\n",
        "  - cat.5351.jpg\n",
        "  - dog.8898.jpg\n",
        "  - dog.10237.jpg\n",
        "  - cat.11184.jpg  \n",
        "  \n",
        "  Jak myślisz dlaczego te zdjęcia znalazły się w zbiorze danych treningowych?\n",
        "  \n",
        "Nie będziemy w ramach zajęć poprawiać tego datasetu, zresztą warto mieć świadomość, że wiele z publicznie dostępnych zbiorów danych nie jest perfekcyjna i może zawierać błędy. Stosowane przez nas algorytmy powinny być odporne na obecność takich drobnych błędów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As41_GgD-4XW"
      },
      "source": [
        "image_type = ____\n",
        "image_index = ____\n",
        "show_image(_______, _______)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huXC2X0m-4XW"
      },
      "source": [
        "Wiele zdjęć jest w wysokiej rozdzielczości:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkJqlOfV-4XX"
      },
      "source": [
        "image_type = 'dog'\n",
        "image_index = 12051\n",
        "show_image(image_type, image_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG6VrnhF-4XX"
      },
      "source": [
        "Przy czym poszczególne zdjęcia są w różnych rozmiarach, musimy je przekształcić wszystkie na ten sam rozmiar. Aby oszczędzić czasu na treningu zredukujemy zdjęcia do rozmiaru 80 na 80 pikseli. Korzystamy z argumentu nazwowego `target_size` w napisanej przez nas funkcji `show_image` aby wyświetlić pomniejszony obraz (chcemy 80 na 80 pikseli):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlgpWcDH-4XX"
      },
      "source": [
        "image_type = 'dog'\n",
        "image_index = 12051\n",
        "show_image(image_type, image_index, ____________=(____, ____))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhFB-Yes-4XY"
      },
      "source": [
        "Na takich obrazach będzie uczyć się sieć, cały czas da się rozróżnić w obrazie psa, ale detali jest mniej."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vQ0Nd6x-4XY"
      },
      "source": [
        "## `ImageDataGenerator`\n",
        "Ponieważ będziemy teraz korzystać z większych obrazów niż w przypadku danych Fashion MNIST (`80 x 80` w przeciwieństwie do wcześniejszych `28 x 28`), a ponadto sami musielibyśmy je wszystkie wczytywać, przeskalowywać do odpowiedniego rozmiaru i budować macierz - zastosujemy inne, bardziej elastyczne rozwiązanie.  \n",
        "Zamiast wczytywać wszystkie obrazy i przetrzymywać je na raz w pamięci komputera jako `X_train` oraz `X_test` będziemy obrazy wczytywać dynamicznie podczas treningu z dysku. Takie rozwiązanie ma dodatkowe zalety przy *image augmentation*, z którego skorzystamy później. Korzystamy do tego z obiektu `ImageDataGenerator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEpwDtT6-4XY"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47iHjQI_-4XZ"
      },
      "source": [
        "Tworząc obiekt `ImageDataGenerator` skorzystamy z argumentu nazwowego `rescale` pozwalającego na przeskalowanie wartości pikseli obrazu. Aby przeskalować wartości do zakresu 0 - 1 podamy temu argumentowi wartość `1 / 255` - spowoduje to, że każdy piksel zostanie pomnożony przez tę wartość, a więc podzielony przez `255` - maksymalną wartość piksela w danych RGB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beccTxDG-4Xa"
      },
      "source": [
        "scaling = _________\n",
        "data_gen = ImageDataGenerator(rescale=scaling)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vdLcsjV-4Xa"
      },
      "source": [
        "Teraz skorzystamy z metody `.flow_from_directory` utworzonego obiektu aby stworzyć wersję generatora, która pobiera obrazy z folderu. Jako pierwszy argument podajemy ścieżkę do folderu `train` - generator sam już rozpozna, że mamy do czynienia z dwoma klasami: `cat` oraz `dog` na podstawie nazw podfolderów obecnych w folderze treningowym. Dodatkowo korzystamy z argumentów nazwowych:  \n",
        "* `target_size` aby obrazy były pomniejszane do rozdzielczości `80 x 80`\n",
        "* `batch_size` aby na raz z dysku wczytywana była pewna liczba obrazów - my wybierzemy w tym wypadku `25`\n",
        "* `class_mode` za pomocą którego informujemy generator, że mamy do czynienia z zadaniem dychotomicznym (pies vs kot) do którego stosujemy jeden neuron wyjściowy. Informujemy o tym generator podając temu argumentowi wartość `'binary'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsoLMs77-4Xa"
      },
      "source": [
        "train_generator = data_gen.flow_from_directory(\n",
        "    r'________________',\n",
        "    target_size=(__, __), ________=____, ________=____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aEqStCs-4Xb"
      },
      "source": [
        "Generator powinien zakomunikować, że znalazł 22500 obrazów należących do 2 klas. Tekstowe etykiety klas są zgodne z nazwami podfolderów. Numeryczne etykiety klas również pochodzą od nazw folderów: konkretnie od posortowanej kolejności ich nazw. Możemy te informacje sprawdzić za pomocą atrybutu `class_indices` naszego generatora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ExLDua-4Xb"
      },
      "source": [
        "________.________"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyuwr2Aq-4Xb"
      },
      "source": [
        "Generator na raz będzie wczytywał `125` zdjęć z dysku. Przy czym generator pobierałby obrazy z folderu w nieskończoność, gdy dojdzie do ostatniego zdjęcia, wraca do pierwszego. Dlatego musimy sami pilnować ile \"pobrań\" z folderu stanowi przejście przez wszystkie zdjęcia - jeżeli chcemy aby w jedenej epoce treningowej sieć oglądała wszystkie zdjęcia treningowe. Sprawdzamy w związku z tym na ile \"paczek\" po 125 obrazów dzieli się nasz zbiór treningowy 22500 zdjęć:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2J39KLg-4Xc"
      },
      "source": [
        "____ / ____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEFqMhXL-4Xc"
      },
      "source": [
        "## Budujemy sieć"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFhMRPLQ-4Xc"
      },
      "source": [
        "Do sieci typu CNN potrzebujemy dodatkowych warstw:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXIGnL2C-4Xc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syEBvQjw-4Xd"
      },
      "source": [
        "### Instrukcje\n",
        "Zbuduj sieć postępując wedle poniższych zaleceń:\n",
        "* co najmniej trzy warstwy splotowe (w sumie)\n",
        "* max pooling co najmniej dwa razy\n",
        "* max pooling za każdym razem po jednej lub dwóch warstwach splotowych\n",
        "* pierwsza warstwa splotowa musi mieć co najmniej 8 filtrów\n",
        "* nie używaj filtrów mniejszych niż `(3, 3)`\n",
        "* każda kolejna warstwa splotowa powinna mieć większą ilość filtrów niż poprzednia\n",
        "* jeżeli chcesz użyć więcej niż trzech warstw splotowych - częściej stosuj max pooling po dwóch warstwach splotowych niż jednej (max pooling najbardziej redukuje rozmiar obrazu, więc przy zbyt wielu można łatwo doprowadzić\n",
        "* po zakończeniu części z warstwami splotowymi (i max poolingiem)\n",
        "  dodaj warstwę `Flatten`, a następnie warstę `Dense` o dowolnej liczbie neuronów większej niż 25\n",
        "* na sam koniec warstwa `Dense` z jednym neuronem (bo mamy tylko dwie kategorie, więc neuron wyjściowy będzie nam mówił \"czypies\" - niska aktywność znaczyć będzie kot) o aktywacji `'sigmoid'`\n",
        "\n",
        "Im więcej warstw splotowych tym potencjalnie wyższa będzie poprawność Twojej sieci.\n",
        "\n",
        "### Przykłady dodawania pojedynczych warstw:\n",
        "* dodajemy warstwę splotową:\n",
        "  ```python\n",
        "  model.add(Conv2D(20, (5, 5), activation='relu'))\n",
        "  ```\n",
        "* dodajemy warstwę max pooling:\n",
        "  ```python\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  ```\n",
        "  (możecie zmienić `pool_size` na np `(3, 3)` aby uzyskać trzykrotną redukcję obrazu)\n",
        "* dodajemy warstwę flatten:\n",
        "  ```python\n",
        "  model.add(Flatten())\n",
        "  ```\n",
        "* dodajemy warstwę Dense:\n",
        "  ```python\n",
        "  `model.add(Dense(32, activation='relu'))\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V5Ha0We-4Xd"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# schemat pierwszej warstwy jest już dodany, wystarczy go uzupełnić\n",
        "model.add(Conv2D(__, (_, _), input_shape=(80, 80, 3), activation='relu'))\n",
        "\n",
        "# kolejne warstwy...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# na koniec, flatten i dense\n",
        "\n",
        "\n",
        "# i neuron wyjściowy, który mówi pies albo kot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac-trS6_-4Xd"
      },
      "source": [
        "# i kompilujemy tak jak zwykle\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i9aaKRi-4Xd"
      },
      "source": [
        "Sprawdź podsumowanie modelu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTW7rNt-4Xe"
      },
      "source": [
        "model.______()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94TC-Cm9-4Xe"
      },
      "source": [
        "*uwaga, poniższy komentarz dotyczy jednej sieci, którą zbuduję, wasza może być inna*  \n",
        "Zauważ, że sieć ma pięć warstw splotowych oraz w sumie ponad 120 tysięcy parametrów (wag połączeń) - a na współczesne standardy zbudowaliśmy dosyć małą sieć.  \n",
        "Zastanów się w której warstwie skupia się najwięcej parametrów sieci - znajdziesz to w tabeli powyżej. Dlaczego tak jest?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhzTH9lo-4Xe"
      },
      "source": [
        "Do treningu korzystamy teraz nie z metody `.fit()`, ale `.fit_generator()` ponieważ podawać będziemy sieci jako pierwszy argument generator obrazów wczytujący je bezpośrednio z dysku.\n",
        "Trening dużej sieci na komputerze bez wspomagania GPU będzie trwał długo, z tego względu ustawimy liczbę epok tylko na `10` (przy takiej liczbie epok będziemy mieli ograniczoną poprawność, ale w ramach projektu będziecie mieli szanse potrenować sieci splotowe dłużej). Dodatkowo używając zbyt wielu epokach możemy przetrenować sieć doprowadzając do świetnej poprawności na danych treningowych, ale słabej na danych testowych (ale takie ryzyko jest przy dużo większej liczbie epok niż 10). Ryzyko przetrenowania jest całkiem realne ponieważ nie stosujemy żadnej regularyzacji. O regularyzacji opowiemy sobie później.  \n",
        "Argumentowi `steps_per_epoch` musisz podać wartość numeryczną, którą sprawdzaliśmy jeszcze przed treningiem sieć - pomyśl jaką."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDr8VOw5-4Xf"
      },
      "source": [
        "history = model.fit_generator(________, epochs=____, steps_per_epoch=____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNqn9yI-4Xf"
      },
      "source": [
        "Zauważ że już po drugim przejściu przez dane (epoce) poprawność wynosi ok. 75% i stosunkowo szybko rośnie w kolejnych przejściach. To może niestety być zbyt piękne aby było prawdziwe - sugeruje że (przynajmniej częściowo) sieć zapamiętuje przykłady zamiast wyuczyć się wzorców pomagających rozpoznać psy i koty. Sprawdźmy to - zobaczmy jaką mamy poprawność na danych treningowych i testowych:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXzdW5dC-4Xf"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Correctness', fontsize=12)\n",
        "plt.grid(color=(0.85, 0.85, 0.85))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWPqIkfJ-4Xf"
      },
      "source": [
        "Moglibyśmy sieć trenować jeszcze dłużej, ale przydałby się nam do tego stacjonarny komputer z porządną kartą graficzną.\n",
        "Sprawdzimy teraz poprawność na danych treningowych już wytrenowanej sieci (uwaga, może to chwilę potrwać!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCpmozP-4Xg"
      },
      "source": [
        "loss, acc = model.evaluate_generator(____________, steps=180)\n",
        "print('Poprawność na danych treningowych: {:.3f}%'.format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJn_ZACU-4Xg"
      },
      "source": [
        "Poprawność powinna wynosić coś między 70% a 90% (to zależy od złożoności trenowanej sieci - ja przy pierwszym treningu miałem 92%, a przy drugim 88%, ale kożystałem z 6 warstw splotowych). Ciekawi nas teraz czy podobnie wysoką poprawność otrzymamy na danych testowych.\n",
        "\n",
        "Aby sprawdzić poprawność na danych testowych musisz utworzyć generator obrazów dla folderu `validate` - tak samo jak robiliśmy to dla folderu `train`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fozCcMsk-4Xg"
      },
      "source": [
        "data_gen_val = ________\n",
        "validate_generator = ___________"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpJk8KOg-4Xg"
      },
      "source": [
        "data_gen_val = ImageDataGenerator(rescale=______)\n",
        "\n",
        "validate_generator = data_gen_val.flow_from_directory(\n",
        "    r'_____________________________________',\n",
        "    target_size=(80, 80), batch_size=125,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUN17W31-4Xg"
      },
      "source": [
        "loss, acc = model.evaluate_generator(_______________, steps=180)\n",
        "print('Poprawność na danych testowych: {:.3f}%'.format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffs-w6aV-4Xh"
      },
      "source": [
        "Poprawność na danych testowych jest znacząco wyższa od 75% (u mnie: 86% za pierwszym razem, 85% za drugim), więc model nauczył się czegoś sensownego, ale jest też niższa od poprawności na danych treningowych (u mnie o 6%), a więc możemy mieć do czynienia z przetrenowaniem (*overfitting*). Spróbujemy temu zapobiec później dodając do sieci regularyzację oraz image augmentation.  \n",
        "Zanim jednak przejdziemy do tego kroku zrobimy analizę predykcji sieci.\n",
        "Zaczniemy od wczytania kilku obrazów z danych walidacyjnych i sprawdzenia predykcji sieci:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3aT5n6y-4Xh"
      },
      "source": [
        "from emosie import load_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDzfBLq-4Xh"
      },
      "source": [
        "Wczytamy najpierw 25 obrazów kotów, jako pierwszy argument podajemy folder treningowy zawierający koty, argumenty nazwowe powinny być jasne:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0lKu1he-4Xh"
      },
      "source": [
        "cat, y_cat = load_images(r'________',\n",
        "                         n_images=____, rescale=____, target_size=(___, ___))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGqnpPHO-4Xh"
      },
      "source": [
        "Zobacz sobie kształt macierzy `cat`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnWiyzpK-4Xi"
      },
      "source": [
        "cat._____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "vQsHmyyK-4Xi"
      },
      "source": [
        "oraz zawartość `y_cat`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Cl2v0a-4Xi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpReNput-4Xi"
      },
      "source": [
        "Teraz wczytamy tyle samo obrazów psów (teraz podajemy folder trenigowy dla psów):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afDEuFIb-4Xi"
      },
      "source": [
        "dog, y_dog = load_images(r'________',\n",
        "                         n_images=____, rescale=____, target_size=(___, ___))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueBxk-TU-4Xj"
      },
      "source": [
        "Porównaj wartości `y` dla psów i kotów, z czymś powinny Ci się one zgadzać:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X3JoQIR-4Xj"
      },
      "source": [
        "y_cat[0], y_dog[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFXoS-Wq-4Xj"
      },
      "source": [
        "Wreszcie wyświetlmy któryś z obrazów z macierzy `dog`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j6WnUfx-4Xj"
      },
      "source": [
        "plt.imshow(dog[___])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39LRZkx-4Xk"
      },
      "source": [
        "oraz predykcję modelu dla tego obrazu (dodatkowy nawias kwadratowy wokół indeksownika prowadzi do zachowania wymiaru - **przykład prowadzącego**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSacZUnm-4Xk"
      },
      "source": [
        "model.predict(dog[[___]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1BO8TVB-4Xk"
      },
      "source": [
        "Co oznacza otrzymana wartość? Przypomnij sobie co mówiliśmy o predykcjach sieci gdy analizowaliśmy dane Fashion MNIST oraz zastanów się ile teraz mamy neuronów na wyjściu i co one nam mówią? Zastanów się co mogłaby oznaczać predykcja 0, a co predykcja 1, a wreszcie jak interpretować wartości pośrednie (między 0 a 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mnhqc-K-4Xk"
      },
      "source": [
        "Zrób to samo dla któregoś obrazu kota:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOhIn4qb-4Xl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llv7AEdY-4Xl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iylzw0lb-4Xl"
      },
      "source": [
        "Narysujmy teraz obraz z predykcją w tytule. Przeczytaj poniższy kod i uzupełnij `_____` w zmiennej tekstowej `msg`. Możesz zmieniać wartość `idx` aby zobaczyć różne obrazy. Aby zamiast psa zobaczyć jakiś obraz kota zmień w drugiej linijce `dog` na `cat`, a w trzeciej `y_dog` na `y_cat`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LJp84SI-4Xl"
      },
      "source": [
        "idx = 13\n",
        "img = dog[[idx]]\n",
        "true_label = y_dog[idx]\n",
        "\n",
        "labels = ['kot', 'pies']\n",
        "pred = model.________(img)[0, 0]\n",
        "\n",
        "msg = 'Predykcja: {:.2f}% pewności, że to _____,\\nnaprawdę to {}'\n",
        "msg = msg.format(pred * 100, labels[true_label])\n",
        "\n",
        "plt.imshow(img[0])\n",
        "plt.axis('off')\n",
        "plt.title(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVNH54--4Xl"
      },
      "source": [
        "Połączymy teraz macierze `dog` oraz `cat` w jedną macierz `X_test` oraz wektory `y_dog` i `y_cat` w jeden wektor `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7AHFv4d-4Xm"
      },
      "source": [
        "X_test = np.concatenate([___, ___])\n",
        "y_test = np.concatenate([___, ___])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxPI8I-O-4Xm"
      },
      "source": [
        "Sprawdźmy ich kształt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REkXyhZU-4Xm"
      },
      "source": [
        "print(X_test.____)\n",
        "print(y_test.____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40yMIMnv-4Xm"
      },
      "source": [
        "Wygenerujmy teraz predykcję dla wszystkich obrazów:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj_T963D-4Xm"
      },
      "source": [
        "preds = model.predict(____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m46jgZWQ-4Xm"
      },
      "source": [
        "i porównamy z poprawnymi odpowiedziami na wykresie poniżej:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cCAz6-U-4Xn"
      },
      "source": [
        "plt.plot(_____[:, 0], label='predicted')\n",
        "plt.plot(_____, label='true')\n",
        "\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLiUPDwO-4Xn"
      },
      "source": [
        "Widzimy, że nawet w tych losowo wybranych 50 obrazach (25 kotów i 25 psów) sieć często nie jest pewna i dosyć często popełnia też błędy. Teraz wyświetlimy wszystkie wybrane 50 zdjęć posortowane względem wartości predykcji sieci. Na czerwono zobaczysz błędne predykcje:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yL5XXu8-4Xn"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=10, ncols=5, figsize=(15, 30))\n",
        "\n",
        "# znajdujemy kolejność sortującą od najwyższej do najniższej poprawności\n",
        "idx_ord = np.argsort(preds[:, 0])[::-1]\n",
        "\n",
        "colors = ['red', 'green']\n",
        "for idx in range(len(idx_ord)):\n",
        "    # wybieramy dany obraz\n",
        "    img_idx = idx_ord[idx]\n",
        "    img = X_test[img_idx]\n",
        "    \n",
        "    # znajdujemy predykcję dla niego\n",
        "    this_pred = preds[img_idx, 0]\n",
        "    categ = np.round(this_pred)\n",
        "\n",
        "    # sprawdzamy czy predykcja jest poprawna\n",
        "    corr = y_test[img_idx] == categ\n",
        "\n",
        "    # przekształcamy indeks na adres kolumny i wiersza\n",
        "    row = int(np.floor(idx / 5))\n",
        "    col = int(idx - row * 5)\n",
        "    \n",
        "    # wyświetlamy obraz\n",
        "    ax[row, col].imshow(img)\n",
        "    ax[row, col].set_axis_off()\n",
        "    \n",
        "    # dodajemy tytuł\n",
        "    msg = '{:.2f}%'.format(this_pred * 100)\n",
        "    ax[row, col].set_title(msg, color=colors[int(corr)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qkou-D4-4Xn"
      },
      "source": [
        "## Image augmentation\n",
        "*image augmentation* to forma tworzenia częściowo nowych danych do treningu w oparciu o dane które już mamy. Opiera się na założeniu, że jeżeli zdjęcie przedstawia np. psa, to pewne operacje na tym obrazie jak np. przybliżenie, obrót, przesunięcie itp. cały czas nie zmieniają kategorii obiektu obecnego na zdjęciu. Innymi słowy: jeżeli obrócimy zdjęcie kota o 25 stopni i zrobimy zoom 10% to cały czas zdjęcie przedstawia kota. W ten sposób możemy zwiększyć ilość zdjęć treningowych dla sieci.\n",
        "Zobacz przykład poniżej:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhssy0k-4Xn"
      },
      "source": [
        "check_gen = ImageDataGenerator(rescale=scaling, zoom_range=[0.8, 1.2], horizontal_flip=True,\n",
        "                              rotation_range=45, width_shift_range=0.2, height_shift_range=0.2)\n",
        "check_generator = check_gen.flow_from_directory(\n",
        "    r'C:\\Users\\mmagn\\Dropbox\\DANE\\ML\\psy_vs_koty\\check_aug',\n",
        "    target_size=(80, 80), batch_size=1, class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTBIUQH3-4Xo"
      },
      "source": [
        "fig, ax = plt.subplots(ncols=5, nrows=5, figsize=(12, 12))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for idx, (X, y) in enumerate(check_generator):\n",
        "    if idx >= 25:\n",
        "        break\n",
        "    ax[idx].imshow(X[0])\n",
        "    ax[idx].set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUvRHLJ8-4Xo"
      },
      "source": [
        "Aby oszczędzić czas - zamiast tworzyć i trenować sieć od nowa, my będziemy kontynuować trening poprzedniej sieci, korzystając tylko z innego generatora obrazów.  \n",
        "(gdy wywołujemy metodę `.fit()` modelu po raz drugi, to faktycznie kontynuujemy trening, jeżeli chcemy zrestetować model najłatwiej jest utworzyć go od nowa - tzn. np. odpalić jeszcze raz komórkę, w której definiujemy model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrUAqSKG-4Xo"
      },
      "source": [
        "aug_gen = ImageDataGenerator(rescale=scaling, zoom_range=[0.8, 1.2], horizontal_flip=True,\n",
        "                              rotation_range=45, width_shift_range=0.2, height_shift_range=0.2)\n",
        "augmented_generator = aug_gen.flow_from_directory(\n",
        "    r'__________________________________________',\n",
        "    target_size=(80, 80), batch_size=125,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOM3Wfer-4Xo"
      },
      "source": [
        "Uwaga, trening z modyfikacjami obrazu trwa jeszcze wolniej niż wcześniej ponieważ każdy obraz nie jest tylko wczytywany z dysku, ale jeszcze modyfikowany. Postępy w treningu będą też mniejsze z kolejnymi epokami, ponieważ zadanie jest trudniejsze: sieć nie może już polegać na sztywnym zapamiętywaniu pewnych własności zdjęć - musi nauczyć się teraz rozpoznawać cechy obrazów, które będą niezmienne względem przesunięć, obrotu, przybliżenia itp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly559PQr-4Xo"
      },
      "source": [
        "history2 = model.fit_generator(augmented_generator, epochs=10, steps_per_epoch=180)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8wfUp94-4Xp"
      },
      "source": [
        "plt.plot(history2.history['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIFkmrJF-4Xp"
      },
      "source": [
        "Kiedy jednak testujemy sieć na danych testowych, nie stosujemy już modyfikacji obrazu. Modyfikacje to tylko zabieg mający wspomóc uczenie sieci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-Chs_x-4Xp"
      },
      "source": [
        "loss, acc = model.evaluate_generator(validate_generator, steps=180)\n",
        "print('Poprawność na danych testowych to teraz: {:.3f}%'.format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWLZYrEs-4Xp"
      },
      "source": [
        "Poprawność powinna trochę podskoczyć. Aby mieć jednak dobre porównanie treningu z oraz bez modyfikacji obrazu, musielibyśmy: a) zresetować model i trenować go od początku z modyfikacjami obrazu oraz b) trenować go dłużej - ponieważ trening z modyfikacjami jest trudniejszy.  \n",
        "\n",
        "Moglibyśmy na przykład trenować model z/bez modyfikacji za każdym razem tak długo, aż osiągnie poprawność 95% na danych treningowych. Do takiego trenowania warunkowego przydaje się obiekt `EarlyStopping` - ale o tym powiemy sobie następnym razem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D20_lLRR-4Xp"
      },
      "source": [
        "## Regularyzacja sieci\n",
        "Budujemy całą sieć tak samo jak wcześniej, dodajemy jednak `Dropout` do jednej z ostatnich warstw.\n",
        "Dropout to prosty sposób regularyzacji - z danej warstwy losowo co pewien czas usuwana jest część neuronów. Prowadzi to do dużo wolniejszego uczenia się, ale zapobiega sytuacji w której neurony bądź ich kombinacje zapamiętują konkretne przykłady treningowe. \n",
        "`Dropout(0.5)` prowadzi do wyrzucenia 50% neuronów przy każdym etapie treningowym. W naszym wypadku chcemy odrzucać właśnie 50% neuronów przy treningu.\n",
        "\n",
        "### Ćwiczenie\n",
        "Przeklej poniżej oryginalną definicję sieci. Dodaj dropout po warstwie `Flatten`. Pamiętaj że dodajemy element do sieci za pomocą `model.add()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzycOCA4-4Xp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAyiGWYj-4Xq"
      },
      "source": [
        "Regularyzacja prowadzi do dużo wolniejszego uczenia się, dlatego tym razem będziemy trenować przez więcej epok - co najmniej 20.\n",
        "To trochę potrwa, także cierpliwości..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGEkRhcY-4Xq"
      },
      "source": [
        "# tutaj trenuj model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvy6ENYz-4Xq"
      },
      "source": [
        "# sprawdź jego poprawność"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d8VvSTP-4Xq"
      },
      "source": [
        "Inną strategią jest tzw. *transfer learning* czyli skorzystanie z sieci wcześniej wytrenowanej na milionach zdjęć (jest sporo takich dostępnych publicznie - wliczając kilka bardzo znanych architektur takich jak np. `'Inception'` czy `'ResNet'`) i dotrenowanie jej do naszego zastosowania. Robimy to zwykle podmieniając w takiej wytrenowanej sieci kilka ostatnich pięter na np. kilkaset neuronów `Dense` pozwalających na klasyfikację pies vs kot. Wtedy trening odbywałby się na takiej hybrydowej sieci - duża część już zastygła, nietrenowana, bo wytrenowana wcześniej w wyłapywaniu z obrazu cech wartościowych dla klasyfikacji różnych obiektów, a tylko końcowa warstwa (albo warstwy) są trenowane z wykorzystaniem posiadanych danych.  \n",
        "Nie przerobimy już jednak tego podejścia na zajęciach."
      ]
    }
  ]
}